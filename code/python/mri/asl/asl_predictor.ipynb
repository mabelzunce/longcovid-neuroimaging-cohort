{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71729320",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.10.9)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Paths and filenames\n",
    "data_partition_path = '/data/'\n",
    "study_data_path = f'{data_partition_path}/UNSAM/CovidProject2/'\n",
    "results_path = f'{study_data_path}/DataAnalysis/'\n",
    "response_excel_filename = f'{study_data_path}/Respuestas.xlsx'\n",
    "summary_excel_filename = f'{study_data_path}/ResumenRespuestas.xlsx'\n",
    "volunteers_excel_filename = f'{study_data_path}/VoluntariosProyectoCovidProlongado.xlsx'\n",
    "\n",
    "# Load ASL CSVs\n",
    "asl_csv_paths = '/home/martin/data/UNSAM/CovidProject2/DataAnalysis/ASL/CleanData/'\n",
    "scov_gm_filename = f'{asl_csv_paths}/scov_total_gm_clean.csv'\n",
    "\n",
    "scov_table = pd.read_csv(scov_gm_filename)\n",
    "\n",
    "# Match groups\n",
    "summary_table = pd.read_excel(summary_excel_filename, sheet_name='resumenTotal')\n",
    "indices_scov = []\n",
    "indices_non_cov = []\n",
    "\n",
    "for i, pid in enumerate(scov_table['participant_id']):\n",
    "    ind = summary_table.index[summary_table['ID'] == pid].tolist()\n",
    "    if ind:\n",
    "        indices_scov.append(ind[0])\n",
    "    else:\n",
    "        print(f'Warning: Subject {pid} not found')\n",
    "        indices_non_cov.append(i)\n",
    "\n",
    "summary_table_matched = summary_table.loc[indices_scov].reset_index(drop=True)\n",
    "group = summary_table_matched['Grupo']\n",
    "scov_table['group'] = group\n",
    "scov_table['sex'] = summary_table_matched['Genero']\n",
    "scov_table['age'] = summary_table_matched['Edad']\n",
    "\n",
    "print(\"COVID count:\", group.value_counts().get('COVID', 0))\n",
    "print(\"CONTROL count:\", group.value_counts().get('CONTROL', 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2f091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scov table only with the main variables:\n",
    "main_vars = ['group', 'sex', 'age', 'GM_vol', 'WM_vol', 'CSF_vol', 'WMH_vol', 'WMH_count', 'TotalGM_B', 'TotalGM_L', 'TotalGM_R']\n",
    "scov_table_main = scov_table[main_vars]\n",
    "print(scov_table_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823c06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Prepare features and labels\n",
    "X = scov_table_main.drop(columns=['group'])\n",
    "y = scov_table_main['group']\n",
    "\n",
    "# numeric + categorical data\n",
    "num_cols = ['age', 'GM_vol', 'WM_vol', 'CSF_vol', 'WMH_vol', 'WMH_count', 'TotalGM_B']#, 'TotalGM_L', 'TotalGM_R']\n",
    "cat_cols = ['sex']\n",
    "\n",
    "# Pre‑processing, rescale numeric features and one-hot encode categorical features\n",
    "preprocess = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "# Pre‑processing, rescale numeric features and one-hot encode categorical features\n",
    "X_preprocessed = preprocess.fit_transform(X)\n",
    "\n",
    "# Find categorical feature indices in the transformed array\n",
    "cat_indices = [i for i, name in enumerate(preprocess.get_feature_names_out()) if 'cat__' in name]\n",
    "# Apply SMOTE with categorical variables\n",
    "smote = SMOTENC(categorical_features=[len(num_cols) + i for i in range(len(cat_cols))],\n",
    "                sampling_strategy='auto',\n",
    "                random_state=42)\n",
    "print(smote)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_preprocessed, y)\n",
    "\n",
    "# Update scov_table and group_shuffled with resampled data\n",
    "scov_table_smote = X_resampled.copy()\n",
    "group_smote = y_resampled.copy()\n",
    "scov_table_smote = pd.DataFrame(scov_table_smote, columns=preprocess.get_feature_names_out())\n",
    "#scov_table_smote['group'] = group_smote \n",
    "indices_shuffle_smote = np.random.permutation(scov_table_smote.shape[0])\n",
    "scov_table_shuffled_smote = scov_table_smote.iloc[indices_shuffle_smote].reset_index(drop=True)\n",
    "group_shuffled_smote = group_smote.iloc[indices_shuffle_smote].reset_index(drop=True)\n",
    "\n",
    "print(scov_table_shuffled_smote)\n",
    "print(\"COVID count:\", group_smote.value_counts().get('COVID', 0))\n",
    "print(\"CONTROL count:\", group_smote.value_counts().get('CONTROL', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe822a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, matplotlib, seaborn\n",
    "print(numpy.__version__, matplotlib.__version__, seaborn.__version__)\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Full table:\n",
    "scov_full_table_smote = scov_table_smote.copy()\n",
    "scov_full_table_smote['group'] = group_smote \n",
    "print(scov_full_table_smote.shape)\n",
    "print(scov_table.shape)\n",
    "\n",
    "# Prepare data for violin plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# scov_table_smote: standardized columns\n",
    "sns.violinplot(\n",
    "    ax=axes[0],\n",
    "    x='group',\n",
    "    y='num__TotalGM_B',\n",
    "    data=scov_full_table_smote,\n",
    "    palette='Set2', inner=\"point\"\n",
    ")\n",
    "axes[0].set_title('TotalGM_B (SMOTE)')\n",
    "\n",
    "sns.violinplot(\n",
    "    ax=axes[1],\n",
    "    x='group',\n",
    "    y='num__age',\n",
    "    data=scov_full_table_smote,\n",
    "    palette='Set2', inner=\"point\"\n",
    ")\n",
    "axes[1].set_title('Age (SMOTE)')\n",
    "\n",
    "sns.violinplot(\n",
    "    ax=axes[2],\n",
    "    x='group',\n",
    "    y='num__WMH_count',\n",
    "    data=scov_full_table_smote,\n",
    "    palette='Set2', inner=\"point\"\n",
    ")\n",
    "axes[2].set_title('WMH_count (SMOTE)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# scov_table: raw columns\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "sns.violinplot(\n",
    "    ax=axes[0],\n",
    "    x='group',\n",
    "    y='TotalGM_B',\n",
    "    data=scov_table,\n",
    "    palette='Set2', inner=\"point\"\n",
    ")\n",
    "axes[0].set_title('TotalGM_B (Raw)')\n",
    "\n",
    "sns.violinplot(\n",
    "    ax=axes[1],\n",
    "    x='group',\n",
    "    y='age',\n",
    "    data=scov_table,\n",
    "    palette='Set2', inner=\"point\"\n",
    ")\n",
    "axes[1].set_title('Age (Raw)')\n",
    "\n",
    "sns.violinplot(\n",
    "    ax=axes[2],\n",
    "    x='group',\n",
    "    y='WMH_count',\n",
    "    data=scov_table,\n",
    "    palette='Set2', inner=\"point\"\n",
    ")\n",
    "axes[2].set_title('WMH_count (Raw)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7965564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Prepare features and labels from SMOTE-augmented data\n",
    "X_aug = scov_table_shuffled_smote\n",
    "y_aug = group_shuffled_smote\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_aug, y_aug, test_size=0.2, random_state=42, stratify=y_aug)\n",
    "\n",
    "# Train SVM classifier\n",
    "svm_clf = SVC(kernel='rbf', random_state=42)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute feature importances using permutation importance\n",
    "result = permutation_importance(svm_clf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Display feature importances\n",
    "feature_names = X_aug.columns\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f281bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Prepare features and labels\n",
    "X = scov_table_main.drop(columns=['group'])\n",
    "y = scov_table_main['group']\n",
    "\n",
    "# numeric + categorical data\n",
    "num_cols = ['age', 'GM_vol', 'WM_vol', 'CSF_vol', 'WMH_vol', 'WMH_count', 'TotalGM_B']#, 'TotalGM_L', 'TotalGM_R']\n",
    "cat_cols = ['sex']\n",
    "\n",
    "# Pre‑processing, rescale numeric features and one-hot encode categorical features\n",
    "preprocess = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "])\n",
    "# Pre‑processing, rescale numeric features and one-hot encode categorical features\n",
    "#X_preprocessed = preprocess.fit_transform(X)\n",
    "\n",
    "# Apply SMOTE with categorical variables\n",
    "#smote = SMOTENC(categorical_features=[len(num_cols) + i for i in range(len(cat_cols))],\n",
    "#                sampling_strategy='auto',\n",
    "#                random_state=42)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Build pipeline:  preprocess  →  SMOTE  →  SVM\n",
    "# ------------------------------------------------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    ('prep',  preprocess),\n",
    "    ('smote', SMOTENC(categorical_features=[len(num_cols) + i for i in range(len(cat_cols))],\n",
    "                sampling_strategy='auto',\n",
    "                random_state=42)),\n",
    "    ('svm',   SVC())                      # kernel & params set later by GridSearch\n",
    "])\n",
    "pipe.set_params(svm__class_weight='balanced')\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  Hyper‑parameter grid\n",
    "#     – two kernels   (rbf, poly‑degree3)\n",
    "#     – a modest sweep of C and gamma\n",
    "# ------------------------------------------------------------------\n",
    "param_grid = {\n",
    "    'svm__kernel': ['rbf', 'poly'],\n",
    "    'svm__degree': [3],                  # ignored for 'rbf'\n",
    "    'svm__C':      [0.1, 1, 10],\n",
    "    'svm__gamma':  ['scale', 0.01, 0.001],\n",
    "    'svm__class_weight': [None,\n",
    "                          {'CONTROL': 2, 'COVID': 1},\n",
    "                          {'CONTROL': 3, 'COVID': 1}]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='balanced_accuracy',   # good for slight imbalance\n",
    "                    cv=cv,\n",
    "                    n_jobs=-1,                     # parallel if CPU allows\n",
    "                    verbose=2)\n",
    "\n",
    "grid.fit(X, y)                    # ⬅ whole dataset goes in; CV handles split\n",
    "\n",
    "print(f\"Best model:  {grid.best_params_}\")\n",
    "print(f\"CV balanced accuracy: {grid.best_score_:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Final evaluation on a held‑out test set (optional)\n",
    "# ------------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\nHeld‑out accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute feature importances using permutation importance\n",
    "result = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Display feature importances\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36467ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with weights instead of SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Prepare features and labels\n",
    "X = scov_table_main.drop(columns=['group'])\n",
    "y = scov_table_main['group']\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Build pipeline:  preprocess  →  SVM\n",
    "# ------------------------------------------------------------------\n",
    "pipe = Pipeline(steps=[\n",
    "    ('prep',  preprocess),\n",
    "    ('svm',  SVC(class_weight='balanced'))\n",
    "])\n",
    "# ------------------------------------------------------------------\n",
    "# 3.  Hyper‑parameter grid\n",
    "#     – two kernels   (rbf, poly‑degree3)\n",
    "#     – a modest sweep of C and gamma\n",
    "# ------------------------------------------------------------------\n",
    "param_grid = {\n",
    "    'svm__kernel': ['rbf', 'poly'],\n",
    "    'svm__degree': [3],                  # ignored for 'rbf'\n",
    "    'svm__C':      [0.1, 1, 10],\n",
    "    'svm__gamma':  ['scale', 0.01, 0.001]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring='balanced_accuracy',   # good for slight imbalance\n",
    "                    cv=cv,\n",
    "                    n_jobs=-1,                     # parallel if CPU allows\n",
    "                    verbose=2)\n",
    "\n",
    "grid.fit(X, y)                    # ⬅ whole dataset goes in; CV handles split\n",
    "\n",
    "print(f\"Best model:  {grid.best_params_}\")\n",
    "print(f\"CV balanced accuracy: {grid.best_score_:.3f}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4.  Final evaluation on a held‑out test set (optional)\n",
    "# ------------------------------------------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\nHeld‑out accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Compute feature importances using permutation importance\n",
    "result = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "importances = result.importances_mean\n",
    "\n",
    "# Display feature importances\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False)\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca15388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 0. Load / define your data  (Long‑COVID = 1, Control = 0)\n",
    "# ---------------------------------------------------------------\n",
    "# Prepare features and labels\n",
    "X = scov_table_main.drop(columns=['group'])\n",
    "y = scov_table_main['group'].map({'CONTROL': 0, 'COVID': 1})  # ensure 0/1 labels\n",
    "\n",
    "# numeric + categorical data\n",
    "num_cols = ['age', 'GM_vol', 'WM_vol', 'CSF_vol', 'WMH_vol', 'WMH_count', 'TotalGM_B']#, 'TotalGM_L', 'TotalGM_R']\n",
    "cat_cols = ['sex']\n",
    "\n",
    "X = scov_table_main[['sCOV', 'age', 'sex']]   # or whatever your DataFrame is called\n",
    "y = scov_table_main['group'].map({'CONTROL': 0, 'COVID': 1})  # ensure 0/1 labels\n",
    "\n",
    "# Identify numeric vs categorical columns\n",
    "num_cols = ['sCOV', 'age']\n",
    "cat_cols = ['sex']                            # will be one‑hot encoded\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1. Pre‑processing: scale numerics, one‑hot categoricals\n",
    "# ---------------------------------------------------------------\n",
    "preprocess = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', OneHotEncoder(drop='first'), cat_cols)   # avoid dummy trap\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2. Logistic‑lasso model  (L1 penalty → automatic feature shrinkage)\n",
    "# ---------------------------------------------------------------\n",
    "logit = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='saga',\n",
    "    class_weight='balanced',   # compensates for imbalance\n",
    "    max_iter=5000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocess),\n",
    "    ('clf',  logit)\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 3. Cross‑validation performance\n",
    "# ---------------------------------------------------------------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    'bal_acc': 'balanced_accuracy',\n",
    "    'roc_auc': 'roc_auc',\n",
    "}\n",
    "\n",
    "cv_results = cross_validate(pipe, X, y, cv=cv, scoring=scoring,\n",
    "                            return_estimator=True, n_jobs=-1)\n",
    "\n",
    "print(f\"Balanced accuracy (CV mean ± SD): \"\n",
    "      f\"{cv_results['test_bal_acc'].mean():.3f} ± {cv_results['test_bal_acc'].std():.3f}\")\n",
    "print(f\"ROC‑AUC          (CV mean ± SD): \"\n",
    "      f\"{cv_results['test_roc_auc'].mean():.3f} ± {cv_results['test_roc_auc'].std():.3f}\")\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 4. Fit on the full data to inspect coefficients / odds ratios\n",
    "# ---------------------------------------------------------------\n",
    "pipe.fit(X, y)\n",
    "\n",
    "# Extract the trained coefficients (after preprocessing)\n",
    "feature_names = (\n",
    "    pipe.named_steps['prep']\n",
    "        .get_feature_names_out(num_cols + cat_cols)\n",
    ")\n",
    "\n",
    "coefs = pipe.named_steps['clf'].coef_.flatten()\n",
    "odds_ratios = np.exp(coefs)           # OR = e^β\n",
    "\n",
    "odds_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'coef (β)': coefs,\n",
    "    'odds_ratio': odds_ratios\n",
    "}).sort_values('odds_ratio', ascending=False)\n",
    "\n",
    "print(\"\\nOdds ratios (L1‑regularised model):\")\n",
    "print(odds_df.to_string(index=False, float_format=\"%.3f\"))\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 5. (Optional) Plot ROC curve for visual appraisal\n",
    "# ---------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_estimator(pipe, X, y)\n",
    "plt.title('Logistic‑lasso ROC curve (five‑fold CV pooled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79cf205",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
